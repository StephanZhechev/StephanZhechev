Hi, Iâ€™m @StephanZhechev

I have a PhD in computational topology and my current interests are in the direction of understanding and modeling real world data.
I find fascination in deep and complicated theories but at heart I am a problem solver.

# My interests

1. **Machine learning.** I find learning theory and the foundations of machine learning very interested and I have spent some nontrivial
amount of time educating myself in this direction. However, my real interest is in applying techniques to solve problems. When working with data,
I tend to follow Occam's razor principle but for good or bad, linear regression and regular expressions can only solve a limited set of problems. 

1. **Classical statistical models.** Something I have used a lot are GLM(M), GAM(M) etc. These are very powerful models that often provide
just the right solution to the problem at hand.

1. **Topological data analysis.** This is a toolbox of geometric and topological techniques for exploring the *shape* of data and extracting
features that are in some sense robust to noise. Unlike XGBoost, these techniques do not provide a key that unlocks all doors but in some cases they
can be incredibly powerful.

1. **Mathematics.** I consider myself a mathematician and I will always love mathematics, especially algebraic topology, homotopy theory and algebra.
I also have a crush on algebraic geometry.


# My current projects span:

1. Developing models for understanding the real estate market in some European countries. 

1. Text mining from different types of documents in different languages. This includes the full spectrum starting from
OCR or parsing some strange HTML code, all the way to text classification, text extraction and summarization (extractive. One day
when I manage to produce 1M times larger set of well labelled data, I might try abstractive summarization as well).

# My philosophy on working with data

* Domain knowledge and common sense are very important and often underestimated.

* Real world data is messy and for most tasks, cleaning and proper labelling are the more
challenging task than the actual modelling.

* The simplest kernel machine will often crush a well tuned powerful model, e.g. XGBoost, if the proper kernel for the data is constructed.

* Blindly throwing data you don't understand, to a neural network because it will learn the right features, will very rarely solve your problem.

* Difficult tasks require sophisticated solutions. Complicated models exist for a reason.
